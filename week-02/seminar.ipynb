{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zwRfuC6RDb1B"
   },
   "source": [
    "# Seminar 2. PyTorch\n",
    "Hi! Today we are going to study PyTorch. We'll compare numpy and PyTorch commands, rewrite our previous neural network in two ways.\n",
    "\n",
    "!!! GPU ON !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ilG0uJwVcke4"
   },
   "outputs": [],
   "source": [
    "! pip install numpy scikit-learn matplotlib seaborn mnist torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cMKPD9TZdokn"
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "import numpy as np\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7gsxpRimFHF-"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b7xxXYAeFofM"
   },
   "source": [
    "## Numpy vs Pytorch\n",
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kbIPHFs6FmkB"
   },
   "outputs": [],
   "source": [
    "a = [1. , 1.4 , 2.5]\n",
    "print(f\"Simple way: {torch.tensor(a)}\")\n",
    "print(f\"Zeros:\\n {torch.zeros((2,3))}\")\n",
    "print(f\"Range: {torch.arange(0, 10)}\")\n",
    "print(f\"Complicated range: {torch.arange(4, 12, 2)}\")\n",
    "print(f\"Space: {torch.linspace(1, 4, 6)}\")\n",
    "print(f\"Identity matrix:\\n {torch.eye(4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sWKCkXaSGK1U"
   },
   "source": [
    "### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OHFgnpzOF5yb"
   },
   "outputs": [],
   "source": [
    "print(f\"From 0 to 1: {torch.rand(1)}\")\n",
    "print(f\"Vector from 0 to 1: {torch.rand(5)}\")\n",
    "print(f\"Vector from 0 to 10: {torch.randint(10, size=(5,))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7EmP3g0wGfzT"
   },
   "source": [
    "### Matrix Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KfUdENnEF8-l"
   },
   "outputs": [],
   "source": [
    "a = torch.arange(10).type(torch.FloatTensor)\n",
    "b = torch.linspace(-10, 10, 10)\n",
    "print(f\"a: {a}\\nshape: {a.size()}\")\n",
    "print(f\"b: {a}\\nshape: {b.size()}\")\n",
    "print(f\"a + b: {a + b},\\n a * b: {a * b}\")\n",
    "print(f\"Dot product: {a.dot(b)}\")\n",
    "print(f\"Mean: {a.mean()}, STD: {a.std()}\")\n",
    "print(f\"Sum: {a.sum()}, Min: {a.min()}, Max: {a.max()}\")\n",
    "print(f\"Reshape:\\n{a.reshape(-1, 1)}\\nshape: {a.reshape(-1, 1).size()}\")\n",
    "c = a.reshape(-1, 1).repeat(1, 5)\n",
    "print(f\"Repeat:\\n{c}\\nshape: {c.size()}\")\n",
    "print(f\"Transpose:\\n{c.T}\\nshape: {c.T.size()}\")\n",
    "print(f\"Unique items: {torch.unique(c)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pdhrhXj9H0m6"
   },
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bHqXM0bQGrRv"
   },
   "outputs": [],
   "source": [
    "a = torch.arange(100).reshape(10, 10)\n",
    "print(f\"Array:\\n{a}\\nshape: {a.size()}\")\n",
    "print(f\"Get first column: {a[:, 0]}\")\n",
    "print(f\"Get last row: {a[-1, :]}\")\n",
    "print(f\"Add new awis:\\n{a[:, np.newaxis]}\\nshape: {a[:, np.newaxis].size()}\")\n",
    "print(f\"Specific indexing:\\n{a[4:6, 7:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rFQ0OwEkIHu8"
   },
   "source": [
    "### Numpy <-> Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oueWvyMzH6sZ"
   },
   "outputs": [],
   "source": [
    "a = torch.normal(mean=torch.zeros(2,4))\n",
    "a.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VRCr6c78QeH1"
   },
   "outputs": [],
   "source": [
    "b = np.random.normal(size=(2, 4))\n",
    "torch.from_numpy(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fJyktewrROPL"
   },
   "source": [
    "### CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JshOGbX0RAb1"
   },
   "outputs": [],
   "source": [
    "a = torch.normal(mean=torch.zeros(2,4))\n",
    "b = torch.normal(mean=torch.zeros(2, 4))\n",
    "print(f\"a:\\n{a}\\nb:\\n{b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mKUxAfveR6iQ"
   },
   "outputs": [],
   "source": [
    "a = a.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "klvLnHmaSDbk"
   },
   "outputs": [],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "11l9FxZVSEDL"
   },
   "outputs": [],
   "source": [
    "(a + b.cuda()).cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DFkGBACsSmL4"
   },
   "source": [
    "### Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yr46uuNNSR_U"
   },
   "outputs": [],
   "source": [
    "a = torch.randn(2, requires_grad=True)\n",
    "b = torch.normal(mean=torch.zeros(2))\n",
    "\n",
    "c = torch.dot(a, b)\n",
    "print(f'a:\\n{a}\\nb:\\n{b}\\n(a,b): {c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jmiq2lLnSvO4"
   },
   "outputs": [],
   "source": [
    "c.backward()\n",
    "print(f'a:\\n{a}\\nb:\\n{b}\\n(a,b): {c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O8I2iLEyS3dU"
   },
   "outputs": [],
   "source": [
    "print(f\"Grad a: {a.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YFD2nov7UDlf"
   },
   "source": [
    "Add function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-z2P8UECTnEO"
   },
   "outputs": [],
   "source": [
    "a = torch.randn(2, requires_grad=True)\n",
    "b = torch.normal(mean=torch.zeros(2))\n",
    "c = torch.ones(1, requires_grad=True)\n",
    "\n",
    "d = torch.sigmoid(torch.dot(a, b) + c)\n",
    "print(f'a:\\n{a}\\nb:\\n{b}\\nSigmoid( (a,b) ): {d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ur_QA6xbTzeG"
   },
   "outputs": [],
   "source": [
    "print(f\"Grad a: {a.grad}\\nGrad c: {c.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PsheM7soT6sw"
   },
   "outputs": [],
   "source": [
    "d.backward()\n",
    "print(f\"Grad a: {a.grad}\\nGrad c: {c.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yf9pO1XJUFZI"
   },
   "source": [
    "Okay, what about vectors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ginrHkBT_HC"
   },
   "outputs": [],
   "source": [
    "a = torch.randn(2, requires_grad=True)\n",
    "b = torch.normal(mean=torch.zeros(2))\n",
    "\n",
    "c = a * b\n",
    "c.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-sNYtrJ3YxV3"
   },
   "source": [
    "## Neural Network. Rewind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_MKsdG6GdorV"
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "import mnist\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "waQtAlplIh6N"
   },
   "outputs": [],
   "source": [
    "images = mnist.train_images() / 255\n",
    "labels = mnist.train_labels()\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BOHbffeqHyeF"
   },
   "outputs": [],
   "source": [
    "def get_batches(dataset, batch_size):\n",
    "    X = dataset[0].reshape(-1, 28 * 28)\n",
    "    Y = dataset[1]\n",
    "    n_samples = X.shape[0]\n",
    "    \n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    for start in range(0, n_samples, batch_size):\n",
    "        end = min(start + batch_size, n_samples)\n",
    "        \n",
    "        batch_idx = indices[start:end]\n",
    "    \n",
    "        yield torch.FloatTensor(X[batch_idx]), torch.LongTensor(Y[batch_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R402HnG8ULdl"
   },
   "outputs": [],
   "source": [
    "class CustomLinear:\n",
    "    def __init__(self, in_size, out_size):\n",
    "        \"\"\"\n",
    "        Simple linear layer\n",
    "        \"\"\"\n",
    "        self.in_size = in_size\n",
    "        self.out_size = out_size\n",
    "\n",
    "        self.w = ...  # torch.randn\n",
    "        self.b = ...  # torch.randn\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return ...  # torch.mm\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.w.grad = None\n",
    "        self.b.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vzDzCXmtZivn"
   },
   "outputs": [],
   "source": [
    "class CustomNeuralNetwork:\n",
    "    def __init__(self, dims, activation=\"sigmoid\"):\n",
    "        \"\"\"\n",
    "        Simple deep networks, that joins several linear layers. \n",
    "        \"\"\"\n",
    "        self.dims = dims\n",
    "\n",
    "        self.linears = ...  # list of linear layers\n",
    "        if activation == \"sigmoid\":\n",
    "            self.activation = torch.sigmoid\n",
    "        elif activation == \"relu\":\n",
    "            self.activation = torch.relu\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return ...\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for l in self.linears:\n",
    "            l.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LZtMZC_dbmFS"
   },
   "outputs": [],
   "source": [
    "class CustomCrossEntropy:\n",
    "    def __call__(self, x, target):\n",
    "        return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t47gvIlUkFpT"
   },
   "outputs": [],
   "source": [
    "def simple_sgd(model, config):\n",
    "    with torch.no_grad():\n",
    "        for l in model.linears:\n",
    "            l.w -= config['learning_rate'] * l.w.grad\n",
    "            l.b -= config['learning_rate'] * l.b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ER9Cs5jaoNi"
   },
   "outputs": [],
   "source": [
    "net = CustomNeuralNetwork((28 * 28, 10, 10))\n",
    "criterion = CustomCrossEntropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gOQeiTU0Jnkr"
   },
   "outputs": [],
   "source": [
    "optimizer_config = {\n",
    "    \"learning_rate\": 1e-1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5nwAo4jfaxry"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer_config, n_epoch=20, batch_size=256):\n",
    "    train_logs = {\"Train Loss\": [0,], \"Steps\": [0,]}\n",
    "    valid_logs = {\"Valid Loss\": [0,], \"Valid Accuracy\": [0,], \"Steps\": [0,]}\n",
    "    step = 0\n",
    "    best_valid_loss = np.inf\n",
    "    best_model = None\n",
    "\n",
    "    for i in range(n_epoch):\n",
    "        for x_batch, y_batch in get_batches((X_train, y_train), batch_size):\n",
    "            model.zero_grad()\n",
    "            \n",
    "            predictions = model(x_batch)\n",
    "            loss = criterion(predictions, y_batch)\n",
    "\n",
    "            loss.backward()\n",
    "            \n",
    "            simple_sgd(model, optimizer_config)      \n",
    "            \n",
    "            step += 1\n",
    "            train_logs[\"Train Loss\"].append(loss.detach().item())\n",
    "            train_logs[\"Steps\"].append(step)\n",
    "\n",
    "        sum_loss = 0\n",
    "        sum_acc = 0\n",
    "        count_valid_steps = 0\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in get_batches((X_valid, y_valid), batch_size):\n",
    "                predictions = model(x_batch)\n",
    "                loss = criterion(predictions, y_batch)\n",
    "                sum_loss += loss.item()\n",
    "                sum_acc += accuracy_score(y_batch, np.argmax(predictions.numpy(), axis=1))\n",
    "                count_valid_steps += 1\n",
    "\n",
    "        valid_logs[\"Valid Loss\"].append(sum_loss / count_valid_steps)\n",
    "        valid_logs[\"Valid Accuracy\"].append(sum_acc / count_valid_steps)\n",
    "        valid_logs[\"Steps\"].append(step)\n",
    "\n",
    "        if best_valid_loss > sum_loss / count_valid_steps:\n",
    "            best_valid_loss = sum_loss / count_valid_steps\n",
    "            best_model = deepcopy(model)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
    "    sns.lineplot(x=\"Steps\", y=\"Train Loss\", data=train_logs, ax=ax[0])\n",
    "    sns.lineplot(x=\"Steps\", y=\"Valid Loss\", data=valid_logs, ax=ax[1])\n",
    "    sns.lineplot(x=\"Steps\", y=\"Valid Accuracy\", data=valid_logs, ax=ax[2])\n",
    "    plt.plot()\n",
    "\n",
    "    return best_model, train_logs, valid_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ufy_8neBa3hG"
   },
   "outputs": [],
   "source": [
    "net, _, _ = train(net, optimizer_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oWnI3eIEeLZT"
   },
   "source": [
    "## Neural Network. Rewind #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sLgLKCUfcCG3"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Linear(nn.Module):\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_size = in_size\n",
    "        self.out_size = out_size\n",
    "\n",
    "        self.w = ...  # nn.Parameter\n",
    "        self.b = ...  # nn.Parameter\n",
    "\n",
    "    def forward(self, x):\n",
    "        return ...  # torch.mm\n",
    "\n",
    "\n",
    "class BatchNorm(nn.Module):\n",
    "    def __init__(self, in_size, alpha=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_size = in_size\n",
    "\n",
    "        self.beta = ...  # nn.Parameter\n",
    "        self.gamma = ...  # nn.Parameter\n",
    "\n",
    "        self.epsilon = 1e-5\n",
    "\n",
    "    def forward(self, x):\n",
    "        return ...\n",
    "\n",
    "\n",
    "class Dropout(nn.Module):\n",
    "    def __init__(self, p=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x):\n",
    "        return ...\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_size, out_size, activation=\"sigmoid\", p=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = Linear(in_size, out_size)\n",
    "        self.dropout = Dropout(p)\n",
    "        self.batch_norm = BatchNorm(out_size)\n",
    "        \n",
    "        if activation == \"sigmoid\":\n",
    "            self.activation = torch.sigmoid\n",
    "        elif activation == \"relu\":\n",
    "            self.activation = torch.relu\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = ...\n",
    "        x = ...\n",
    "        x = ...\n",
    "        return ...\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, dims, activation=\"relu\", p=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.blocks = nn.ModuleList(\n",
    "            list(Block(d_0, d_1, activation=activation, p=p) for d_0, d_1 in zip(dims[:-2], dims[1:-1]))\n",
    "        )\n",
    "        self.cl = Linear(dims[-2], dims[-1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for m in self.blocks:\n",
    "            x = m(x)\n",
    "        return self.cl(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PcqQ6AwPczjI"
   },
   "outputs": [],
   "source": [
    "net = Net((28 * 28, 100, 10), p=0.1).cuda()\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cZtluygsczgm"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o2iqWQojL3J7"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, n_epoch=20, batch_size=256, device=\"cpu\"):\n",
    "    train_logs = {\"Train Loss\": [0,], \"Steps\": [0,]}\n",
    "    valid_logs = {\"Valid Loss\": [0,], \"Valid Accuracy\": [0,], \"Steps\": [0,]}\n",
    "    step = 0\n",
    "    best_valid_loss = np.inf\n",
    "    best_model = Nonein\n",
    "\n",
    "    for i in range(n_epoch):\n",
    "        for x_batch, y_batch in get_batches((X_train, y_train), batch_size):\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            predictions = model(x_batch)\n",
    "            loss = criterion(predictions, y_batch)\n",
    "\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()   \n",
    "            \n",
    "            step += 1\n",
    "            train_logs[\"Train Loss\"].append(loss.detach().item())\n",
    "            train_logs[\"Steps\"].append(step)\n",
    "\n",
    "        sum_loss = 0\n",
    "        sum_acc = 0\n",
    "        count_valid_steps = 0\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in get_batches((X_valid, y_valid), batch_size):\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "\n",
    "                predictions = model(x_batch)\n",
    "                loss = criterion(predictions, y_batch)\n",
    "                sum_loss += loss.item()\n",
    "                sum_acc += accuracy_score(y_batch.cpu().numpy(), np.argmax(predictions.cpu().numpy(), axis=1))\n",
    "                count_valid_steps += 1\n",
    "\n",
    "            valid_logs[\"Valid Loss\"].append(sum_loss / count_valid_steps)\n",
    "            valid_logs[\"Valid Accuracy\"].append(sum_acc / count_valid_steps)\n",
    "            valid_logs[\"Steps\"].append(step)\n",
    "\n",
    "            if best_valid_loss > sum_loss / count_valid_steps:\n",
    "                best_valid_loss = sum_loss / count_valid_steps\n",
    "                best_model = deepcopy(net)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
    "    sns.lineplot(x=\"Steps\", y=\"Train Loss\", data=train_logs, ax=ax[0])\n",
    "    sns.lineplot(x=\"Steps\", y=\"Valid Loss\", data=valid_logs, ax=ax[1])\n",
    "    sns.lineplot(x=\"Steps\", y=\"Valid Accuracy\", data=valid_logs, ax=ax[2])\n",
    "    plt.plot()\n",
    "\n",
    "    return best_model, train_logs, valid_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QDkpB7TtL3IU"
   },
   "outputs": [],
   "source": [
    "net, _, _ = train(net, optimizer, device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mcOEa7lcjiyO"
   },
   "source": [
    "### Neural Network. Rewind #3. Logging\n",
    "\n",
    "Logging systems:\n",
    "- [Tensorboard](https://pytorch.org/docs/stable/tensorboard.html)\n",
    "- [WandB](https://www.wandb.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fjRHFJXSjn81"
   },
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_size, out_size, activation=\"relu\", p=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_size = in_size\n",
    "        self.out_size = out_size\n",
    "\n",
    "        if activation == \"sigmoid\":\n",
    "            self.activation = nn.Sigmoid\n",
    "        elif activation == \"relu\":\n",
    "            self.activation = nn.ReLU\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            ...  # Linear, BatchNorm1d, Dropout, Activation\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "net = nn.Sequential(Block(28 * 28, 100, p=0.2), nn.Linear(100, 10)).cuda()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=1e-1)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QV1AxNFbfapY"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cgo_htQZfamn"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4qWa59wKf5Jd"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, n_epoch=20, batch_size=256, device=\"cpu\"):\n",
    "    writer = SummaryWriter(Path(\"logs\") / datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    step = 0\n",
    "    best_valid_loss = np.inf\n",
    "    best_model = None\n",
    "\n",
    "    for i in range(n_epoch):\n",
    "        for x_batch, y_batch in get_batches((X_train, y_train), batch_size):\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            predictions = model(x_batch)\n",
    "            loss = criterion(predictions, y_batch)\n",
    "\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()   \n",
    "            \n",
    "            step += 1\n",
    "            writer.add_scalar(\"Train Loss\", loss.detach().item(), step)\n",
    "\n",
    "        sum_loss = 0\n",
    "        sum_acc = 0\n",
    "        count_valid_steps = 0\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in get_batches((X_valid, y_valid), batch_size):\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "\n",
    "                predictions = model(x_batch)\n",
    "                loss = criterion(predictions, y_batch)\n",
    "                sum_loss += loss.item()\n",
    "                sum_acc += accuracy_score(y_batch.cpu().numpy(), np.argmax(predictions.cpu().numpy(), axis=1))\n",
    "                count_valid_steps += 1\n",
    "\n",
    "            writer.add_scalar(\"Valid Loss\", sum_loss / count_valid_steps, step)\n",
    "            writer.add_scalar(\"Valid Accuracy\", sum_acc / count_valid_steps, step)\n",
    "\n",
    "            if best_valid_loss > sum_loss / count_valid_steps:\n",
    "                best_valid_loss = sum_loss / count_valid_steps\n",
    "                best_model = deepcopy(net)\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qptL6E_Mf5G5"
   },
   "outputs": [],
   "source": [
    "net = train(net, optimizer, device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SuzkIqc0f5FG"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7W1zyKnXFdxt"
   },
   "source": [
    "## Spoiler - train loop with [Catalyst](https://github.com/catalyst-team/catalyst)\n",
    "\n",
    "- [A comprehensive step-by-step guide to basic and advanced features](https://github.com/catalyst-team/catalyst#step-by-step-guide)\n",
    "- [Docs](https://catalyst-team.github.io/catalyst/)\n",
    "- [What is Runner?](https://catalyst-team.github.io/catalyst/api/core.html#runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Y_cQnMeJJiU"
   },
   "outputs": [],
   "source": [
    "! pip install catalyst==21.04.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gm2SIio7f5Cd"
   },
   "outputs": [],
   "source": [
    "import typing as tp\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from catalyst import dl, metrics, utils\n",
    "from catalyst.contrib.datasets import MNIST\n",
    "from catalyst.data.transforms import ToTensor\n",
    "\n",
    "model = nn.Sequential(nn.Flatten(), nn.Linear(28 * 28, 10))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.02)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "loaders = {\n",
    "    \"train\": DataLoader(\n",
    "        MNIST(os.getcwd(), train=True, download=True, transform=ToTensor()), batch_size=32,\n",
    "    ),\n",
    "    \"valid\": DataLoader(\n",
    "        MNIST(os.getcwd(), train=False, download=True, transform=ToTensor()), batch_size=32,\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "class CustomRunner(dl.Runner):\n",
    "    def predict_batch(self, batch: tp.Tuple[torch.Tensor, torch.Tensor]) -> torch.Tensor:\n",
    "        # model inference step\n",
    "        return self.model(batch[0].to(self.device))\n",
    "\n",
    "    def on_loader_start(self, runner):\n",
    "        super().on_loader_start(runner)\n",
    "        self.meters = {\n",
    "            key: metrics.AdditiveValueMetric(compute_on_call=False)\n",
    "            for key in [\"loss\", \"accuracy01\", \"accuracy03\"]\n",
    "        }\n",
    "\n",
    "    def handle_batch(self, batch: tp.Tuple[torch.Tensor, torch.Tensor]):\n",
    "        # model train/valid step\n",
    "        # unpack the batch\n",
    "        x, y = batch\n",
    "        # run model forward pass\n",
    "        y_hat = self.model(x)\n",
    "        # compute the loss\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        # compute the metrics\n",
    "        accuracy01, accuracy03 = metrics.accuracy(y_hat, y, topk=(1, 3))\n",
    "        # log metrics\n",
    "        self.batch_metrics.update(\n",
    "            {\"loss\": loss, \"accuracy01\": accuracy01, \"accuracy03\": accuracy03}\n",
    "        )\n",
    "        for key in [\"loss\", \"accuracy01\", \"accuracy03\"]:\n",
    "            self.meters[key].update(self.batch_metrics[key].item(), self.batch_size)\n",
    "        # run model backward pass\n",
    "        if self.is_train_loader:\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "    def on_loader_end(self, runner):\n",
    "        for key in [\"loss\", \"accuracy01\", \"accuracy03\"]:\n",
    "            self.loader_metrics[key] = self.meters[key].compute()[0]\n",
    "        super().on_loader_end(runner)\n",
    "\n",
    "\n",
    "runner = CustomRunner()\n",
    "\n",
    "# model training\n",
    "runner.train(\n",
    "    engine=dl.DeviceEngine(device=utils.get_device()),\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    loaders=loaders,\n",
    "    criterion=criterion,\n",
    "    logdir=Path(\"logs\") / datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
    "    num_epochs=5,\n",
    "    verbose=True,\n",
    "    load_best_on_end=True,\n",
    ")\n",
    "\n",
    "# model inference\n",
    "for prediction in runner.predict_loader(loader=loaders[\"valid\"]):\n",
    "    assert prediction.detach().cpu().numpy().shape[-1] == 10\n",
    "\n",
    "features_batch = next(iter(loaders[\"valid\"]))[0]\n",
    "# model tracing\n",
    "utils.trace_model(model=runner.model, batch=features_batch)\n",
    "# model quantization\n",
    "utils.quantize_model(model=runner.model)\n",
    "# model pruning\n",
    "utils.prune_model(model=runner.model, pruning_fn=\"l1_unstructured\", amount=0.8)\n",
    "# onnx export\n",
    "# utils.onnx_export(model=runner.model, batch=features_batch, file=\"./logs/mnist.onnx\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZUz3o_kJJIHe"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "seminar_done.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:py37-dev]",
   "language": "python",
   "name": "conda-env-py37-dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
